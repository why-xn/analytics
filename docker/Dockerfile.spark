FROM apache/spark-py:v3.2.1

USER root

ARG spark_version=3.2.1

RUN apt update -y && \
    apt install -y wget vim net-tools 

RUN apt install -y apt-transport-https apt-utils gnupg2 curl \
  && curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - \
  && echo "deb https://apt.kubernetes.io/ kubernetes-xenial main" | tee -a /etc/apt/sources.list.d/kubernetes.list \
  && apt update \
  && apt install -y kubectl

# Download hadoop SDK
RUN wget https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.2.2/hadoop-aws-3.2.2.jar \
         -O /opt/spark/jars/hadoop-aws-3.2.2.jar

# Download AWS SDK
RUN wget https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.99/aws-java-sdk-bundle-1.12.99.jar  \
         -O /opt/spark/jars/aws-java-sdk-bundle-1.12.99.jar

# Download iceburg
#
RUN wget https://search.maven.org/remotecontent?filepath=org/apache/iceberg/iceberg-spark-runtime-3.2_2.12/0.13.1/iceberg-spark-runtime-3.2_2.12-0.13.1.jar \
         -O /opt/spark/jars/iceberg-spark-runtime-3.2_2.12-0.13.1.jar

# Kafka 
RUN wget https://repo1.maven.org/maven2/org/apache/spark/spark-streaming-kafka-0-10_2.12/${spark_version}/spark-streaming-kafka-0-10_2.12-${spark_version}.jar \
        -O /opt/spark/jars/spark-streaming-kafka-0-10_2.12-${spark_version}.jar

RUN wget https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/${spark_version}/spark-sql-kafka-0-10_2.12-${spark_version}.jar \
        -O /opt/spark/jars/spark-sql-kafka-0-10_2.12-${spark_version}.jar

RUN wget https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.0.0/kafka-clients-3.0.0.jar \
        -O /opt/spark/jars/kafka-clients-3.0.0.jar


WORKDIR /opt/spark/work-dir

# Specify the User that the actual main process will run as
USER ${spark_uid}
